#!/usr/bin/env python3
"""
ä»æ—¥å¿—ä¸­æå–å½“å‰å·²å®Œæˆçš„SCBenchç»“æœï¼Œæ¨¡æ‹Ÿå¢é‡ä¿å­˜çš„æ•ˆæœ
"""
import re
import json
from datetime import datetime

def extract_progress_from_log(log_file="/home/pai/data/PQCache/scbench_run.log"):
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–å·²å®Œæˆçš„æ ·æœ¬ä¿¡æ¯"""
    
    print("ğŸ“Š ä»æ—¥å¿—ä¸­æå–SCBench RepoQAè¿›å±•...")
    
    # ç”¨äºå­˜å‚¨ç»“æœçš„å˜é‡
    completed_samples = []
    current_sample = None
    current_turns = []
    
    # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    turn_pattern = r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \| INFO.*Turn (\d+): Generated (\d+) chars in ([\d.]+)s"
    sample_pattern = r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \| INFO.*Completed sample (\d+)/(\d+)"
    
    try:
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                
                # æ£€æŸ¥Turnå®Œæˆ
                turn_match = re.search(turn_pattern, line)
                if turn_match:
                    timestamp, turn_idx, chars, time_taken = turn_match.groups()
                    turn_info = {
                        "turn_idx": int(turn_idx) - 1,  # è½¬æ¢ä¸º0-based
                        "timestamp": timestamp,
                        "generated_chars": int(chars),
                        "generation_time": float(time_taken),
                        "prediction_preview": f"Generated {chars} characters"  # å®é™…å†…å®¹åœ¨æ—¥å¿—ä¸­éš¾ä»¥æå–
                    }
                    current_turns.append(turn_info)
                
                # æ£€æŸ¥Sampleå®Œæˆ
                sample_match = re.search(sample_pattern, line)
                if sample_match:
                    timestamp, sample_idx, total_samples = sample_match.groups()
                    sample_idx = int(sample_idx) - 1  # è½¬æ¢ä¸º0-based
                    
                    # ä¿å­˜å‰ä¸€ä¸ªæ ·æœ¬çš„ä¿¡æ¯
                    if current_turns:
                        sample_info = {
                            "sample_id": sample_idx,
                            "completion_timestamp": timestamp,
                            "turns": current_turns.copy(),
                            "total_turns": len(current_turns)
                        }
                        completed_samples.append(sample_info)
                        current_turns = []  # é‡ç½®
                
                # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯100ä¸‡è¡Œï¼‰
                if line_num % 1000000 == 0:
                    print(f"   å¤„ç†äº† {line_num:,} è¡Œæ—¥å¿—...")
    
    except FileNotFoundError:
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return []
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å‡ºé”™: {e}")
        return []
    
    return completed_samples

def save_extracted_results(completed_samples, output_file="extracted_scbench_progress.jsonl"):
    """å°†æå–çš„ç»“æœä¿å­˜ä¸ºJSONLæ ¼å¼"""
    
    if not completed_samples:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„æ ·æœ¬")
        return
    
    print(f"ğŸ’¾ ä¿å­˜ {len(completed_samples)} ä¸ªå·²å®Œæˆæ ·æœ¬åˆ°: {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for sample in completed_samples:
            for turn in sample["turns"]:
                # æ¨¡æ‹ŸSCBenchè¾“å‡ºæ ¼å¼
                result_item = {
                    "id": sample["sample_id"],
                    "turn_idx": turn["turn_idx"],
                    "prediction": turn["prediction_preview"],
                    "ground_truth": "N/A (not available in log)",
                    "lang": "unknown",
                    "repo": "unknown", 
                    "generation_time": turn["generation_time"],
                    "input_length": "N/A",
                    "output_length": turn["generated_chars"],
                    "completion_timestamp": turn["timestamp"],
                    "extracted_from_log": True
                }
                json.dump(result_item, f, ensure_ascii=False)
                f.write('\n')
    
    print("âœ… ç»“æœå·²ä¿å­˜")

def analyze_progress(completed_samples):
    """åˆ†æè¿›å±•æƒ…å†µ"""
    
    if not completed_samples:
        print("âŒ æ²¡æœ‰å¯åˆ†æçš„æ•°æ®")
        return
    
    print(f"\nğŸ“ˆ è¿›å±•åˆ†æ:")
    print(f"å·²å®Œæˆæ ·æœ¬æ•°: {len(completed_samples)}/88 ({len(completed_samples)/88*100:.1f}%)")
    
    total_turns = sum(len(sample["turns"]) for sample in completed_samples)
    print(f"å·²å®Œæˆè½®æ¬¡: {total_turns}")
    
    # è®¡ç®—å¹³å‡ç”Ÿæˆæ—¶é—´
    all_times = []
    all_chars = []
    for sample in completed_samples:
        for turn in sample["turns"]:
            all_times.append(turn["generation_time"])
            all_chars.append(turn["generated_chars"])
    
    if all_times:
        avg_time = sum(all_times) / len(all_times)
        avg_chars = sum(all_chars) / len(all_chars)
        print(f"å¹³å‡ç”Ÿæˆæ—¶é—´: {avg_time:.1f} ç§’")
        print(f"å¹³å‡ç”Ÿæˆå­—ç¬¦æ•°: {avg_chars:.0f} å­—ç¬¦")
        
        # æ—¶é—´åˆ†æ
        min_time = min(all_times)
        max_time = max(all_times)
        print(f"ç”Ÿæˆæ—¶é—´èŒƒå›´: {min_time:.1f}s - {max_time:.1f}s")
    
    # æœ€æ–°å®Œæˆçš„æ ·æœ¬
    if completed_samples:
        latest = completed_samples[-1]
        print(f"æœ€æ–°å®Œæˆæ ·æœ¬: #{latest['sample_id']} (æ—¶é—´: {latest['completion_timestamp']})")

def main():
    print("ğŸ” å¼€å§‹æå–SCBench RepoQAå½“å‰è¿›å±•...")
    
    # æå–è¿›å±•
    completed_samples = extract_progress_from_log()
    
    if completed_samples:
        # åˆ†æè¿›å±•
        analyze_progress(completed_samples)
        
        # ä¿å­˜ç»“æœ
        save_extracted_results(completed_samples)
        
        print(f"\nğŸ‰ æˆåŠŸæå–äº† {len(completed_samples)} ä¸ªå·²å®Œæˆæ ·æœ¬çš„ä¿¡æ¯ï¼")
        print("ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: extracted_scbench_progress.jsonl")
        
    else:
        print("âŒ æœªèƒ½ä»æ—¥å¿—ä¸­æå–åˆ°æœ‰æ•ˆçš„è¿›å±•ä¿¡æ¯")

if __name__ == "__main__":
    main()
