#!/usr/bin/env python3
"""
å…·ä½“ä¾‹å­ï¼šKVç¼“å­˜tokené€‰æ‹©æœºåˆ¶
æ¼”ç¤ºTOPKå’ŒRECENT_RATIOå¦‚ä½•å·¥ä½œ
"""

import numpy as np

def create_concrete_example():
    """åˆ›å»ºä¸€ä¸ªå…·ä½“çš„ä¾‹å­"""
    print("ğŸ¯ å…·ä½“ä¾‹å­ï¼šç§‘å­¦è®ºæ–‡é—®ç­”åœºæ™¯")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªç§‘å­¦è®ºæ–‡çš„tokenåºåˆ—
    tokens = [
        # ä½ç½®0-31: SINKåŒºåŸŸ (æ°¸è¿œä¿ç•™)
        "Abstract:", "This", "paper", "presents", "a", "novel", "approach", "...",
        "[SINKåŒºåŸŸå…±32ä¸ªtoken - æ°¸è¿œä¿ç•™]",
        
        # ä½ç½®32-8999: ä¸­é—´çš„é•¿æ–‡æ¡£å†…å®¹
        "Introduction", "section", "describes", "the", "problem", "...",
        "Method", "section", "explains", "our", "algorithm", "...", 
        "Results", "show", "significant", "improvement", "...",
        "Discussion", "reveals", "important", "insights", "...",
        "[ä¸­é—´8968ä¸ªtokençš„é•¿æ–‡æ¡£å†…å®¹]",
        
        # ä½ç½®9000-9967: é—®é¢˜å’Œå¼€å§‹ç”Ÿæˆçš„å›ç­”
        "Question:", "What", "is", "the", "main", "contribution", "of", "this", "paper?",
        "Answer:", "The", "main", "contribution", "is", "a", "novel", "...",
        
        # ä½ç½®9968-9999: RECENTåŒºåŸŸ (æœ€è¿‘32ä¸ªtoken - æ°¸è¿œä¿ç•™)
        "algorithm", "that", "significantly", "improves", "performance", "by", "...",
        "[RECENTåŒºåŸŸæœ€å32ä¸ªtoken - æ°¸è¿œä¿ç•™]"
    ]
    
    # æ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡ (æ•°å€¼è¶Šå¤§è¡¨ç¤ºè¶Šé‡è¦)
    attention_weights = {
        # SINKåŒºåŸŸ - ä¸å‚ä¸é€‰æ‹©ï¼Œç›´æ¥ä¿ç•™
        0: 0.0,   # "Abstract:" - SINK
        5: 0.0,   # "novel" - SINK  
        
        # ä¸­é—´åŒºåŸŸ - å‚ä¸é‡è¦æ€§é€‰æ‹©
        32: 0.95,   # "Introduction" - éå¸¸é‡è¦!
        45: 0.85,   # "algorithm" - å¾ˆé‡è¦
        123: 0.90,  # "Method" - å¾ˆé‡è¦  
        234: 0.30,  # "the" - ä¸é‡è¦
        345: 0.25,  # "and" - ä¸é‡è¦
        456: 0.88,  # "Results" - å¾ˆé‡è¦
        567: 0.20,  # "of" - ä¸é‡è¦
        678: 0.82,  # "significant" - é‡è¦
        789: 0.15,  # "a" - ä¸é‡è¦
        890: 0.87,  # "improvement" - å¾ˆé‡è¦
        
        # é—®é¢˜å’Œç­”æ¡ˆåŒºåŸŸ
        9005: 0.92,  # "contribution" - é—®é¢˜å…³é”®è¯
        9010: 0.88,  # "Answer:" - é‡è¦
        9015: 0.85,  # "novel" - é‡è¦
        
        # RECENTåŒºåŸŸ - ä¸å‚ä¸é€‰æ‹©ï¼Œç›´æ¥ä¿ç•™
        9968: 0.0,  # "algorithm" - RECENT
        9999: 0.0,  # æœ€åä¸€ä¸ªtoken - RECENT
    }
    
    return tokens, attention_weights

def demonstrate_selection_process():
    """æ¼”ç¤ºé€‰æ‹©è¿‡ç¨‹"""
    tokens, attention_weights = create_concrete_example()
    
    # å‚æ•°è®¾ç½®
    total_length = 10000
    compress_ratio = 0.1
    sink_size = 32
    recent_size = 32
    topk_ratio = 0.5
    recent_ratio = 0.5
    
    compressed_length = int(total_length * compress_ratio)  # 1000
    available_positions = compressed_length - sink_size - recent_size  # 936
    
    print(f"ğŸ“Š åŸå§‹é•¿åº¦: {total_length} tokens")
    print(f"ğŸ“Š å‹ç¼©å: {compressed_length} tokens")
    print(f"ğŸ“Š å¯åˆ†é…ä½ç½®: {available_positions} tokens")
    print()
    
    # æ­¥éª¤1: å›ºå®šä¿ç•™åŒºåŸŸ
    print("ğŸ”’ ç¬¬1æ­¥: å›ºå®šä¿ç•™åŒºåŸŸ")
    print(f"   SINKåŒºåŸŸ (ä½ç½®0-{sink_size-1}): æ°¸è¿œä¿ç•™")
    print(f"   RECENTåŒºåŸŸ (ä½ç½®{total_length-recent_size}-{total_length-1}): æ°¸è¿œä¿ç•™") 
    print()
    
    # æ­¥éª¤2: å€™é€‰tokenæ±  (é™¤äº†SINKå’ŒRECENTçš„æ‰€æœ‰token)
    candidate_positions = list(range(sink_size, total_length - recent_size))
    print(f"ğŸŠ ç¬¬2æ­¥: å€™é€‰tokenæ± ")
    print(f"   å€™é€‰èŒƒå›´: ä½ç½®{sink_size}åˆ°{total_length-recent_size-1}")
    print(f"   å€™é€‰æ€»æ•°: {len(candidate_positions)} tokens")
    print()
    
    # æ­¥éª¤3: æŒ‰é‡è¦æ€§æ’åº (TOPKé€‰æ‹©)
    print("â­ ç¬¬3æ­¥: é‡è¦æ€§é€‰æ‹© (TOPK)")
    
    # æ¨¡æ‹Ÿè®¡ç®—æ¯ä¸ªå€™é€‰ä½ç½®çš„æ³¨æ„åŠ›æƒé‡
    weighted_candidates = []
    for pos in candidate_positions[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªä½œä¸ºä¾‹å­
        weight = attention_weights.get(pos, np.random.random() * 0.5)  # éšæœºæƒé‡ä½œä¸ºç¤ºä¾‹
        weighted_candidates.append((pos, weight))
    
    # æŒ‰æƒé‡æ’åº
    weighted_candidates.sort(key=lambda x: x[1], reverse=True)
    
    topk_count = int(available_positions * topk_ratio)  # 468ä¸ª
    print(f"   éœ€è¦é€‰æ‹©æœ€é‡è¦çš„: {topk_count} tokens")
    print(f"   æœ€é‡è¦çš„å‡ ä¸ªtoken:")
    
    for i, (pos, weight) in enumerate(weighted_candidates[:8]):
        if pos in attention_weights:
            token_desc = f"ä½ç½®{pos} (æƒé‡{weight:.2f}) - é‡è¦å…³é”®è¯"
        else:
            token_desc = f"ä½ç½®{pos} (æƒé‡{weight:.2f}) - æ™®é€štoken"
        print(f"     #{i+1}: {token_desc}")
    
    print(f"   ... (æ€»å…±é€‰æ‹©{topk_count}ä¸ªæœ€é‡è¦çš„)")
    print()
    
    # æ­¥éª¤4: æŒ‰æ—¶é—´é€‰æ‹© (RECENT_RATIOé€‰æ‹©)
    print("ğŸ•’ ç¬¬4æ­¥: æ—¶é—´å±€éƒ¨æ€§é€‰æ‹© (RECENT_RATIO)")
    
    recent_count = int(available_positions * recent_ratio)  # 468ä¸ª
    print(f"   éœ€è¦é€‰æ‹©æœ€è¿‘çš„: {recent_count} tokens")
    
    # ä»å€™é€‰æ± ä¸­é€‰æ‹©æœ€è¿‘çš„token (ä½ç½®è¶Šå¤§è¶Šè¿‘)
    recent_candidates = sorted(candidate_positions, reverse=True)[:recent_count]
    
    print(f"   é€‰æ‹©çš„æœ€è¿‘tokenèŒƒå›´:")
    print(f"     ä»ä½ç½®{recent_candidates[-1]}åˆ°ä½ç½®{recent_candidates[0]}")
    print(f"     è¿™äº›æ˜¯é—®é¢˜å’Œç­”æ¡ˆå¼€å§‹éƒ¨åˆ†ï¼Œä»¥åŠæ–‡æ¡£ç»“å°¾éƒ¨åˆ†")
    print()
    
    # æ­¥éª¤5: åˆå¹¶å’Œå»é‡
    print("ğŸ”„ ç¬¬5æ­¥: åˆå¹¶ç»“æœ")
    
    # é‡è¦æ€§é€‰æ‹©çš„token
    topk_selected = [pos for pos, _ in weighted_candidates[:topk_count]]
    
    # æ—¶é—´é€‰æ‹©çš„token  
    recent_selected = recent_candidates[:recent_count]
    
    # åˆå¹¶å¹¶å»é‡
    all_selected = list(set(topk_selected + recent_selected))
    overlap_count = len(topk_selected) + len(recent_selected) - len(all_selected)
    
    print(f"   é‡è¦æ€§é€‰æ‹©: {len(topk_selected)} tokens")
    print(f"   æ—¶é—´é€‰æ‹©: {len(recent_selected)} tokens") 
    print(f"   é‡å éƒ¨åˆ†: {overlap_count} tokens (æ—¢é‡è¦åˆæœ€è¿‘)")
    print(f"   æœ€ç»ˆé€‰æ‹©: {len(all_selected)} tokens")
    print()
    
    # æ­¥éª¤6: æœ€ç»ˆåˆ†é…æ€»ç»“
    print("ğŸ“‹ ç¬¬6æ­¥: æœ€ç»ˆç¼“å­˜åˆ†é…")
    total_kept = sink_size + recent_size + len(all_selected)
    print(f"   ğŸ”’ SINKç¼“å­˜: {sink_size} tokens (æ–‡æ¡£å¼€å¤´)")
    print(f"   ğŸ”’ RECENTç¼“å­˜: {recent_size} tokens (æœ€æ–°ç”Ÿæˆ)")
    print(f"   â­ é‡è¦token: ~{len([p for p in topk_selected if p in all_selected])} tokens (é«˜æ³¨æ„åŠ›)")
    print(f"   ğŸ•’ è¾ƒæ–°token: ~{len([p for p in recent_selected if p in all_selected])} tokens (æ—¶é—´å±€éƒ¨æ€§)")
    print(f"   ğŸ“Š æ€»è®¡: {total_kept} tokens (ç›®æ ‡{compressed_length})")

def show_intuitive_example():
    """æ›´ç›´è§‚çš„ä¾‹å­"""
    print("\n" + "="*60)
    print("ğŸ¯ æ›´ç›´è§‚çš„ä¾‹å­ï¼šå¯¹è¯åœºæ™¯")
    print("="*60)
    
    print("å‡è®¾æœ‰ä¸€ä¸ª10000 tokençš„å¯¹è¯ï¼Œå‹ç¼©åˆ°1000ä¸ªtoken:")
    print()
    
    conversation = [
        "ä½ç½®0-31: [ç³»ç»Ÿæç¤º] ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹... (SINKåŒºåŸŸï¼Œæ°¸è¿œä¿ç•™)",
        "ä½ç½®32-5000: [ç”¨æˆ·] è¯·è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸç†...",
        "ä½ç½®5001-8000: [AI] é‡å­è®¡ç®—æ˜¯åŸºäºé‡å­åŠ›å­¦åŸç†... (é•¿å›ç­”)",
        "ä½ç½®8001-9000: [ç”¨æˆ·] é‚£ä¹ˆé‡å­çº ç¼ æ˜¯æ€ä¹ˆå·¥ä½œçš„?",  
        "ä½ç½®9001-9968: [AI] é‡å­çº ç¼ æ˜¯ä¸€ç§å¥‡ç‰¹çš„ç°è±¡...",
        "ä½ç½®9968-9999: [AI] ...å› æ­¤é‡å­çº ç¼ ... (RECENTåŒºåŸŸï¼Œæ°¸è¿œä¿ç•™)"
    ]
    
    print("ğŸ“š å¯¹è¯å†…å®¹:")
    for line in conversation:
        print(f"  {line}")
    print()
    
    print("ğŸ” é€‰æ‹©ç­–ç•¥:")
    print("  1. SINK (32ä¸ª): ç³»ç»Ÿæç¤ºæ°¸è¿œä¿ç•™")
    print("  2. RECENT (32ä¸ª): æœ€æ–°å›ç­”æ°¸è¿œä¿ç•™") 
    print("  3. å‰©ä½™936ä¸ªä½ç½®åˆ†é…:")
    print("     - é‡è¦æ€§50% (468ä¸ª): é€‰æ‹©'é‡å­è®¡ç®—'ã€'é‡å­çº ç¼ 'ç­‰å…³é”®è¯")
    print("     - æ—¶é—´æ€§50% (468ä¸ª): é€‰æ‹©æœ€è¿‘çš„é—®ç­”å†…å®¹")
    print("     - é‡å : ä¸€äº›tokenæ—¢é‡è¦åˆæœ€è¿‘ï¼Œæ‰€ä»¥æ€»æ•°<936")
    print()
    
    print("ğŸ’¡ è¿™æ ·æ—¢ä¿ç•™äº†:")
    print("  âœ“ å¯¹è¯ä¸Šä¸‹æ–‡ (SINK)")
    print("  âœ“ æœ€æ–°çŠ¶æ€ (RECENT)")  
    print("  âœ“ å…³é”®ä¿¡æ¯ (TOPK)")
    print("  âœ“ å±€éƒ¨è¿è´¯æ€§ (RECENT_RATIO)")

if __name__ == "__main__":
    demonstrate_selection_process()
    show_intuitive_example() 