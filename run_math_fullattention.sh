#!/bin/bash
# Full-Attention AIME 2024 æ•°å­¦æ¨ç†è¯„ä¼°
# å¯¹æ¯” PQCache å’Œ Full-Attention çš„æ€§èƒ½å·®å¼‚

set -e

# ç¡®ä¿æ¿€æ´»æ­£ç¡®çš„condaç¯å¢ƒ
source /home/pai/data/miniconda3/etc/profile.d/conda.sh
conda activate pqcache

echo "=========================================="
echo "Full-Attention Mathematics CoT - AIME 2024"
echo "æ•°æ®é›†: AIME 2024"
echo "æ¨¡å‹: Llama-3.1-8B-Instruct"
echo "ä»»åŠ¡: Full-Attention Chain-of-Thought Mathematical Reasoning"
echo "=========================================="

# ä»»åŠ¡é…ç½®
DATASET="aime_2024"
MODEL="llama-3.1"
OUTPUT_DIR="math_cot_results"
MAX_SEQ_LENGTH=32768
MAX_NEW_TOKENS=2048
NUM_EVAL_EXAMPLES=-1  # æ‰€æœ‰æ ·æœ¬
TEMPERATURE=0.0  # ç¡®å®šæ€§ç”Ÿæˆ

# Method configuration - é‡ç‚¹ï¼šä½¿ç”¨full-attention
METHOD="fullattention"
COMPRESSOR="original"  # originalè¡¨ç¤ºä¸å‹ç¼©
DEVICE_ID=2

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=${DEVICE_ID}
export HF_HOME=~/.cache/huggingface
export HF_ENDPOINT=https://hf-mirror.com

echo "æ¨¡å‹: ${MODEL}"
echo "æ•°æ®é›†: ${DATASET}"
echo "è®¾å¤‡: CUDA:${DEVICE_ID}"
echo "æ–¹æ³•: ${METHOD} (compressor: ${COMPRESSOR})"
echo "æœ€å¤§æ–°tokenæ•°: ${MAX_NEW_TOKENS}"
echo "è¯„ä¼°æ ·æœ¬æ•°: ${NUM_EVAL_EXAMPLES}"
echo ""

# è¿è¡Œè¯„ä¼°
PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128" \
TOKENIZERS_PARALLELISM=false \
python run_math_cot_fullattention.py \
    --model ${MODEL} \
    --dataset ${DATASET} \
    --method ${METHOD} \
    --compressor ${COMPRESSOR} \
    --max_seq_length ${MAX_SEQ_LENGTH} \
    --max_new_tokens ${MAX_NEW_TOKENS} \
    --temperature ${TEMPERATURE} \
    --top_p 1.0 \
    --num_eval_examples ${NUM_EVAL_EXAMPLES} \
    --device_id ${DEVICE_ID} \
    --output_dir ${OUTPUT_DIR} \
    --verbose

echo ""
echo "âœ… Full-Attentionè¯„ä¼°å®Œæˆï¼"

# æ˜¾ç¤ºç»“æœæ–‡ä»¶ä½ç½®
RESULT_FILE="${OUTPUT_DIR}/${MODEL}/${DATASET}/fullattention_cot/cot_results_fullattention.jsonl"
if [ -f "$RESULT_FILE" ]; then
    echo "ğŸ“Š ç»“æœæ–‡ä»¶: $RESULT_FILE"
    echo "ğŸ“ˆ æ ·æœ¬æ•°é‡: $(wc -l < "$RESULT_FILE")"
    
    # å¿«é€Ÿç»Ÿè®¡æ­£ç¡®ç‡
    python -c "
import json
correct = 0
total = 0
with open('$RESULT_FILE', 'r') as f:
    for line in f:
        result = json.loads(line.strip())
        total += 1
        if result.get('is_correct', False):
            correct += 1
print(f'ğŸ¯ å¿«é€Ÿç»Ÿè®¡ - æ­£ç¡®: {correct}/{total}, å‡†ç¡®ç‡: {correct/total:.4f} ({correct/total*100:.2f}%)')
"
else
    echo "âŒ ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°: $RESULT_FILE"
fi

echo ""
echo "ğŸ” è¦è¿›è¡Œè¯¦ç»†åˆ†æï¼Œè¯·è¿è¡Œ:"
echo "python eval_aime_2024_results.py --results_file $RESULT_FILE --detailed_analysis"

# nohup ./run_math_fullattention.sh > math_fullattention.log 2>&1 &

#4003186