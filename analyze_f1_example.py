#!/usr/bin/env python3
"""
F1åˆ†æ•°è®¡ç®—ç¤ºä¾‹ - ç†è§£31.25%çš„å«ä¹‰
"""

import re
import string
from collections import Counter

def normalize_answer(s):
    """æ ‡å‡†åŒ–ç­”æ¡ˆï¼šå»é™¤æ ‡ç‚¹ã€å† è¯ã€å¤šä½™ç©ºæ ¼ï¼Œè½¬å°å†™"""
    def remove_articles(text):
        return re.sub(r"\b(a|an|the)\b", " ", text)
    
    def white_space_fix(text):
        return " ".join(text.split())
    
    def remove_punc(text):
        exclude = set(string.punctuation)
        return "".join(ch for ch in text if ch not in exclude)
    
    def lower(text):
        return text.lower()
    
    return white_space_fix(remove_articles(remove_punc(lower(s))))

def f1_score(prediction_tokens, ground_truth_tokens):
    """è®¡ç®—F1åˆ†æ•°"""
    prediction_counter = Counter(prediction_tokens)
    ground_truth_counter = Counter(ground_truth_tokens)
    
    # è®¡ç®—å…±åŒè¯æ±‡æ•°é‡
    common_tokens = prediction_counter & ground_truth_counter
    num_same = sum(common_tokens.values())
    
    if num_same == 0:
        return 0
    
    # è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
    precision = num_same / len(prediction_tokens) if len(prediction_tokens) > 0 else 0
    recall = num_same / len(ground_truth_tokens) if len(ground_truth_tokens) > 0 else 0
    
    # è®¡ç®—F1åˆ†æ•°
    if precision + recall == 0:
        return 0
    
    f1 = 2 * (precision * recall) / (precision + recall)
    return f1

def analyze_qasper_example():
    """åˆ†æQASPERä¾‹å­çš„F1åˆ†æ•°"""
    print("ğŸ¯ QASPER F1åˆ†æ•°è®¡ç®—ç¤ºä¾‹")
    print("=" * 60)
    
    # å®é™…æ•°æ®
    prediction = "The ground truth for fake news is established by a single expert manually inspecting the text field within the tweets and labeling them as containing fake news or not."
    ground_truth = "Ground truth is not established in the paper"
    
    print(f"ğŸ“ æ¨¡å‹å›ç­”:")
    print(f"   {prediction}")
    print()
    print(f"ğŸ“‹ æ ‡å‡†ç­”æ¡ˆ:")
    print(f"   {ground_truth}")
    print()
    
    # æ ‡å‡†åŒ–å¤„ç†
    norm_pred = normalize_answer(prediction)
    norm_gt = normalize_answer(ground_truth)
    
    print(f"ğŸ”§ æ ‡å‡†åŒ–å:")
    print(f"   æ¨¡å‹: {norm_pred}")
    print(f"   æ ‡å‡†: {norm_gt}")
    print()
    
    # åˆ†è¯
    pred_tokens = norm_pred.split()
    gt_tokens = norm_gt.split()
    
    print(f"ğŸ” åˆ†è¯ç»“æœ:")
    print(f"   æ¨¡å‹è¯æ±‡: {pred_tokens}")
    print(f"   æ ‡å‡†è¯æ±‡: {gt_tokens}")
    print()
    
    # è®¡ç®—F1
    f1 = f1_score(pred_tokens, gt_tokens)
    
    print(f"ğŸ“Š F1è®¡ç®—:")
    # æ‰¾å…±åŒè¯æ±‡
    pred_counter = Counter(pred_tokens)
    gt_counter = Counter(gt_tokens)
    common = pred_counter & gt_counter
    
    print(f"   å…±åŒè¯æ±‡: {dict(common)}")
    print(f"   å…±åŒè¯æ•°: {sum(common.values())}")
    print(f"   æ¨¡å‹è¯æ•°: {len(pred_tokens)}")
    print(f"   æ ‡å‡†è¯æ•°: {len(gt_tokens)}")
    
    precision = sum(common.values()) / len(pred_tokens) if len(pred_tokens) > 0 else 0
    recall = sum(common.values()) / len(gt_tokens) if len(gt_tokens) > 0 else 0
    
    print(f"   ç²¾ç¡®ç‡: {precision:.3f} ({sum(common.values())}/{len(pred_tokens)})")
    print(f"   å¬å›ç‡: {recall:.3f} ({sum(common.values())}/{len(gt_tokens)})")
    print(f"   F1åˆ†æ•°: {f1:.3f} ({f1*100:.1f}%)")
    print()

def explain_f1_meaning():
    """è§£é‡ŠF1åˆ†æ•°çš„å«ä¹‰"""
    print("ğŸ’¡ F1åˆ†æ•°å«ä¹‰è§£é‡Š")
    print("=" * 60)
    
    print("ğŸ“ˆ åˆ†æ•°èŒƒå›´:")
    print("   0% - å®Œå…¨ä¸åŒ¹é…")
    print("   25% - ä½åŒ¹é…åº¦")
    print("   50% - ä¸­ç­‰åŒ¹é…åº¦") 
    print("   75% - é«˜åŒ¹é…åº¦")
    print("   100% - å®Œå…¨åŒ¹é…")
    print()
    
    print("ğŸ” 31.25%æ„å‘³ç€:")
    print("   âœ“ æ¨¡å‹ç†è§£äº†é—®é¢˜")
    print("   âœ“ ç»™å‡ºäº†ç›¸å…³å›ç­”")
    print("   âœ“ ä½†ä¸æ ‡å‡†ç­”æ¡ˆç”¨è¯å·®å¼‚è¾ƒå¤§")
    print("   âœ“ åœ¨KVç¼“å­˜å‹ç¼©90%çš„æƒ…å†µä¸‹ä»ä¿æŒç›¸å½“æ€§èƒ½")
    print()
    
    print("âš–ï¸ æ€§èƒ½è¯„ä¼°:")
    print("   - å¯¹äºå‹ç¼©æ¨¡å‹æ¥è¯´ï¼Œ31.25%æ˜¯åˆç†çš„æ€§èƒ½")
    print("   - è¯´æ˜å‹ç¼©åä»èƒ½ç†è§£å¤æ‚é—®é¢˜")
    print("   - å¯èƒ½éœ€è¦è°ƒæ•´å‹ç¼©å‚æ•°æ¥å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡")

if __name__ == "__main__":
    analyze_qasper_example()
    explain_f1_meaning() 